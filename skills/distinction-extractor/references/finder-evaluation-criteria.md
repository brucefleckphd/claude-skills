# Finder Evaluation Criteria

Use this framework to evaluate distinction extractions for quality. Score across six dimensions.

## Scoring Scale (1-10)

| 9-10 | Exceptional | Exceeds standard; no issues |
| 7-8 | Good | Minor quibbles; production-ready |
| 5-6 | Acceptable | Needs some rework |
| 3-4 | Problematic | Significant issues |
| 1-2 | Failed | Fundamental problems |

---

## Dimension 1: Accuracy (Weight: 25%)

Are the identified candidates actually distinctions?

### 9-10
Every confirmed candidate is a genuine distinction. Zero false positives.

### 7-8
1-2 borderline candidates in confirmed list. Minor quibbles.

### 5-6
Several items classified as distinctions that are actually mechanisms, frameworks, or information.

### 3-4
Systematic misclassification — the Finder is confusing information with distinctions regularly.

### 1-2
Most "distinctions" aren't distinctions at all.

**Key checks:**
- Does each confirmed candidate pass all 6 qualification filters?
- Are mechanisms being elevated to distinctions without proper conversion?
- Is information being dressed up as distinction through fancy framing?
- Would the "Hammer Test" pass? (Can you USE it, or do you need to BELIEVE it?)

---

## Dimension 2: Completeness (Weight: 20%)

Did the Finder catch everything in the source material?

### 9-10
Source appears fully mined. No obvious distinctions missed.

### 7-8
1-2 minor candidates missed but nothing critical.

### 5-6
Notable gaps — clear distinctions in the source that weren't extracted.

### 3-4
Major blind spots — the Finder missed a category of distinctions entirely.

### 1-2
Superficial scan — most of the source material wasn't properly analyzed.

**Key checks:**
- Were all signal patterns scanned for (contrasts, binary frames, before/after, collapses)?
- Are there passages in the source that contain implicit distinctions the Finder missed?
- Did the Finder go deep enough into the source, or just scan the surface?

---

## Dimension 3: Classification (Weight: 15%)

Are distinctions correctly typed (Collapsed, Perceptual, Inversion, Domain-Transfer, Stance, Structural)?

### 9-10
Every type assignment is correct and well-reasoned.

### 7-8
Minor misclassifications that don't affect delivery design.

### 5-6
Several classifications are wrong, which would lead to wrong delivery approach.

### 3-4
Type assignments appear random or defaulted.

---

## Dimension 4: A/B Sharpness (Weight: 15%)

Is the A vs B framing clean, binary, and actionable?

### 9-10
Every A/B pair is crisp, concrete, and immediately usable.

### 7-8
Most are sharp. 1-2 are slightly fuzzy.

### 5-6
Several A/B pairs are vague or academic-sounding.

### 3-4
A/B framing is too abstract to produce perceptual shift.

**Key checks:**
- Is the A side described in the STUDENT'S language (how they currently think)?
- Is the B side concrete enough to visualize?
- Is the boundary between A and B immediately clear?

---

## Dimension 5: Program Relevance (Weight: 15%)

Are these distinctions actually useful for your program's students?

### 9-10
Every distinction directly serves the program's learning objectives.

### 7-8
Most are on-target. 1-2 are tangential but still valuable.

### 5-6
Several extracted distinctions belong in a different program.

### 3-4
The extraction isn't tuned to the target audience.

---

## Dimension 6: Deduplication (Weight: 10%)

Are there redundancies, and were they caught?

### 9-10
No duplicates. Cross-references are noted where related distinctions exist.

### 7-8
Minor overlap between 1-2 candidates, noted.

### 5-6
Several candidates are essentially the same distinction in different words.

### 3-4
Significant redundancy not addressed.

---

## Verdict Logic

**PASS (7.0+)** — Extraction is production-quality. Proceed to Expander.

**REVISE (5.0-6.9)** — Specific items need fixing before Expander. List what needs improvement.

**REDO (below 5.0)** — Fundamental issues. Re-extract with adjusted approach.

---

## Operating Principles

1. **Be ruthless on accuracy.** A false positive wastes Expander time and produces a teaching unit that won't land.

2. **Check the source material yourself.** Don't just evaluate what the Finder produced — read the source and independently identify what you'd extract. Then compare.

3. **The qualification test is non-negotiable.** If a candidate doesn't pass 5+ of the 6 filters, it's not confirmed, regardless of how interesting it seems.

4. **Track patterns across evaluations.** If the Finder consistently misclassifies a certain type or misses implicit distinctions, note this for skill improvement.

5. **Score honestly.** A 10/10 means genuinely excellent. Don't inflate. The scores drive improvement.
